{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://md01.rcc.local:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0-cdh6.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f97cac0e2b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import IntegerType, StructType, StructField, StringType\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Final_project').getOrCreate()\n",
    "#change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '6'), ('spark.cores.max', '4'), ('spark.driver.memory','8g')])\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.yarn.jars',\n",
       "  'local:/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/jars/*,local:/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/hive/*'),\n",
       " ('spark.yarn.appMasterEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.sql.queryExecutionListeners',\n",
       "  'com.cloudera.spark.lineage.NavigatorQueryListener'),\n",
       " ('spark.executor.memory', '5g'),\n",
       " ('spark.lineage.log.dir', '/var/log/spark/lineage'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'md01.rcc.local,md02.rcc.local'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '/opt/cloudera/parcels/CDH/lib/spark/python/lib/py4j-0.10.7-src.zip:/opt/cloudera/parcels/CDH/lib/spark/python/lib/pyspark.zip<CPS>/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/python/lib/py4j-0.10.7-src.zip<CPS>/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/spark/python/lib/pyspark.zip'),\n",
       " ('spark.driver.port', '41001'),\n",
       " ('spark.yarn.historyServer.address', 'http://hd01.rcc.local:18088'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1577383759214_3635'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.app.id', 'application_1577383759214_3635'),\n",
       " ('spark.network.crypto.enabled', 'false'),\n",
       " ('spark.executorEnv.MKL_NUM_THREADS', '1'),\n",
       " ('spark.ui.enabled', 'true'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.dynamicAllocation.schedulerBacklogTimeout', '1'),\n",
       " ('spark.yarn.config.gatewayPath', '/opt/cloudera/parcels'),\n",
       " ('spark.extraListeners', 'com.cloudera.spark.lineage.NavigatorAppListener'),\n",
       " ('spark.port.maxRetries', '60'),\n",
       " ('spark.sql.warehouse.dir', '/user/hive/warehouse'),\n",
       " ('spark.app.name', 'Spark Updated Conf'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.log.persistToDfs.enabled', 'true'),\n",
       " ('spark.yarn.config.replacementPath', '{{HADOOP_COMMON_HOME}}/../../..'),\n",
       " ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.driver.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.executor.instances', '32'),\n",
       " ('spark.driver.appUIAddress', 'http://md01.rcc.local:4041'),\n",
       " ('spark.ui.killEnabled', 'true'),\n",
       " ('spark.cores.max', '4'),\n",
       " ('spark.eventLog.dir', 'hdfs://nameservice1/user/spark/applicationHistory'),\n",
       " ('spark.dynamicAllocation.executorIdleTimeout', '60'),\n",
       " ('spark.io.encryption.enabled', 'false'),\n",
       " ('spark.authenticate', 'false'),\n",
       " ('spark.driver.memory', '8g'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS',\n",
       "  'md01.rcc.local:8088,md02.rcc.local:8088'),\n",
       " ('spark.shuffle.service.enabled', 'true'),\n",
       " ('spark.yarn.historyServer.allowTracking', 'true'),\n",
       " ('spark.yarn.appMasterEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.shuffle.service.port', '7337'),\n",
       " ('spark.lineage.enabled', 'true'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.driver.host', 'md01.rcc.local'),\n",
       " ('spark.executor.cores', '6'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.yarn.am.extraLibraryPath',\n",
       "  '/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/lib/hadoop/lib/native'),\n",
       " ('spark.dynamicAllocation.minExecutors', '0'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://md01.rcc.local:8088/proxy/application_1577383759214_3635,http://md02.rcc.local:8088/proxy/application_1577383759214_3635'),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.log.dfsDir', '/user/spark/driverLogs')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datapath\n",
    "path_comments = \"/user/rroongseang/bigdata/comments/\"\n",
    "path_users = \"/user/rroongseang/bigdata/users/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "df = spark.read.json(path_comments+\"politics_json*\")\n",
    "users = spark.read.csv(path_users+\"RA.2019-09.csv\", inferSchema=True, header=True)\n",
    "botusers = sqlContext.read.csv(path_users+'bot_userdata.csv',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6420881"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----------------------+-----------------+----+----------------+-----------+-------------+-------+------+---+-------+-------+---------+------------+-----+------------+---------+------------+-------+\n",
      "|archived|author|author_flair_css_class|author_flair_text|body|controversiality|created_utc|distinguished|  downs|gilded| id|link_id|   name|parent_id|retrieved_on|score|score_hidden|subreddit|subreddit_id|    ups|\n",
      "+--------+------+----------------------+-----------------+----+----------------+-----------+-------------+-------+------+---+-------+-------+---------+------------+-----+------------+---------+------------+-------+\n",
      "| 4921465|     0|               5610956|          5600126|   0|               0|          0|      6288640|6260155|     0|  0|      0|6260155|        0|        1370|    0|     5702021|        0|           0|5162127|\n",
      "+--------+------+----------------------+-----------------+----+----------------+-----------+-------------+-------+------+---+-------+-------+---------+------------+-----+------------+---------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping several columns with missing and irrelevant data\n",
    "#subreddit/subreddit_id is the same for all comments since we are only looking in r/politics.\n",
    "#author flairs are texts + images next to a username that shows up when they post a comment. Most users don't use flairs\n",
    "#name is a unique identifier that is mostly null.\n",
    "#id is a unique identifier for the commment and does not add any value to analysis\n",
    "df = df.drop('archived','author_flair_css_class','author_flair_text',\n",
    "             'subreddit','subreddit_id','name','score_hidden','id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert column types to integers and timestamps\n",
    "\n",
    "df = df.withColumn(\"ups\", df[\"ups\"].cast(IntegerType())) \n",
    "df = df.withColumn(\"downs\", df[\"downs\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"gilded\", df[\"gilded\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"score\", df[\"score\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"retrieved_on\", df[\"retrieved_on\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"controversiality\", df[\"controversiality\"].cast(IntegerType()))\n",
    "df = df.withColumn('created_utc',df[\"created_utc\"].cast(IntegerType()))\n",
    "df = df.withColumn('retrieved_on',df[\"retrieved_on\"].cast(IntegerType()))\n",
    "\n",
    "\n",
    "df = df.withColumn('created_utc',to_timestamp(df[\"created_utc\"]))\n",
    "df = df.withColumn('retrieved_on',to_timestamp(df[\"retrieved_on\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- controversiality: integer (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- downs: integer (nullable = true)\n",
      " |-- gilded: integer (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- retrieved_on: timestamp (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- ups: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill upvote and downvote null values with zeros\n",
    "df = df.fillna({ 'ups':0, 'downs':0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename a user and botuser columns to match for union of dataframe\n",
    "users = users.selectExpr('id',\"name as username\", \"created_utc as acct_creation\",\n",
    "                         \"updated_on\",\"comment_karma\",\"link_karma\")\n",
    "\n",
    "botusers = botusers.selectExpr('username',\"post_karma as link_karma\", \"comment_karma\",\n",
    "                                 \"cake_day as acct_creation\",\"is_bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "#Convert account creation and updated on to timestampps\n",
    "users = users.withColumn('acct_creation',to_timestamp(users[\"acct_creation\"]))\n",
    "users = users.withColumn('updated_on',to_timestamp(users[\"updated_on\"]))\n",
    "\n",
    "#Add column is_bot to users dataframe\n",
    "users = users.withColumn('is_bot',f.lit('False'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast link karma and comment karma as integer type\n",
    "#Convert account creation and updated on to timestamps\n",
    "botusers = botusers.withColumn('link_karma',botusers[\"link_karma\"].cast(IntegerType()))\n",
    "botusers = botusers.withColumn('comment_karma',botusers[\"comment_karma\"].cast(IntegerType()))\n",
    "botusers = botusers.withColumn('acct_creation',botusers[\"acct_creation\"].cast(IntegerType()))\n",
    "botusers = botusers.withColumn('acct_creation',to_timestamp(botusers[\"acct_creation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows from user df that exists in botusers\n",
    "users = users.join(botusers, users.username==botusers.username, \"leftanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append users dataframe with botusers dataframe \n",
    "all_users = users.select('username','acct_creation','comment_karma','link_karma','is_bot')\\\n",
    "            .union(botusers.select('username','acct_creation','comment_karma','link_karma','is_bot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- username: string (nullable = true)\n",
      " |-- acct_creation: timestamp (nullable = true)\n",
      " |-- comment_karma: integer (nullable = true)\n",
      " |-- link_karma: integer (nullable = true)\n",
      " |-- is_bot: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-------------+----------+------+\n",
      "|     username|      acct_creation|comment_karma|link_karma|is_bot|\n",
      "+-------------+-------------------+-------------+----------+------+\n",
      "|MiraranaMogra|2015-05-14 09:58:34|          103|      4902|  True|\n",
      "+-------------+-------------------+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking to see if one of the Russian banned accts is in the users list\n",
    "all_users.filter(all_users.username == 'MiraranaMogra').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|author      |body                                                                                                                                                                                                                                                                                                |\n",
      "+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|BlackToLive |By submitting to an independent, non-profit community, the authors volunteered on a Good Samaritan basis to spread wokeness                                                                                                                                                                         |\n",
      "|Maxwel_Terry|sure it isnt new..                                                                                                                                                                                                                                                                                  |\n",
      "|Peter_Hurst |There are many secret papers in the world: one could grant keys to the White House, other papers may grant the keys to a cozy prison cell. I bet that upper-governmental moguls like Soros and Koch bros own them.                                                                                  |\n",
      "|Maxwel_Terry|Our government is trying to eliminate ISIS and other terrorists from the Middle East for years. Since the Gulf war, i think. Republicans, Democrats, all sorts of warmongers. Where are the results? France is simply helpless.                                                                     |\n",
      "|Maineylops  |This isn't surprising. Sanders knew this was coming and Clinton was confident about winning.                                                                                                                                                                                                        |\n",
      "|Kevin_Milner|Here is some material about Hillary and her ties to oil lobby.\n",
      "http://www.greenpeace.org/usa/campaign-updates/hillary-clintons-connection-oil-gas-industry/                                                                                                                                         |\n",
      "|mr_clampin  |she's really sick                                                                                                                                                                                                                                                                                   |\n",
      "|Maineylops  |Nope ofcourse not. \"99 out of 100\" had no based facts. If Mr. Trump maintains his current level of support in the remaining races, he could win a delegate majority before the convention, but it will be close. '99 of 100' was what my fellow russians with me voiced. it nener turned to  be so. |\n",
      "|Maineylops  |New York Times says..\n",
      "Donald J. Trump - 742\n",
      "Ted Cruz - 505\n",
      "Marco Rubio - 171\n",
      "John Kasich - 143\n",
      "\n",
      "Average results after April 5\n",
      "\n",
      "Trump 44%\n",
      "Cruz 43%\n",
      "Kasich 13%                                                                                                                                        |\n",
      "|Peter_Hurst |Bill accidentally took money from Algeria.\n",
      "\"I am not guilty, this happened subconsciously. I ate honey with my hands and $500,000 stuck to the hands themselves\"                                                                                                                                    |\n",
      "+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking to see if one of the Russian comments show up in the comments.\n",
    "banned = pd.read_csv('bot_accounts2019.csv')['bot_acct'].tolist()\n",
    "\n",
    "df.filter(df.author.isin(banned)).select('author','body').show(truncate = False)\n",
    "\n",
    "#THEY DO!! Nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining data frames\n",
    "df_raw = df.join(all_users, df.author == users.username, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5158836"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of comments matched with users dataframe\n",
    "df_raw.filter(users.username.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5158836"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows where comments authors do not appear in users dataframe\n",
    "df_raw = df_raw.filter(df_raw.is_bot.isNotNull())\n",
    "df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of banned account comments in dataframe\n",
    "df_raw.filter(df_raw.is_bot == 'True').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting comment posted datetime to new column format HHMMSS\n",
    "df_raw = df_raw.withColumn('created_time',concat(format_string(\"%02d\",hour(df_raw['created_utc'])),\n",
    "                                                     format_string(\"%02d\",minute(df_raw['created_utc'])),\n",
    "                                                     format_string(\"%02d\",second(df_raw['created_utc']))))\n",
    "df_raw = df_raw.withColumn('created_time',df_raw['created_time'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove formatting characters\n",
    "df_raw = df_raw.withColumn('body_vec', f.regexp_replace('body', \"[^a-zA-Z0-9\\\\s]\", \"\"))\n",
    "\n",
    "#Next, we will put all letters into lower-case\n",
    "df_raw = df_raw.withColumn('body_vec', lower(col('body_vec')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------------+-------------------+-------------+-----+------+---------+----------+-------------------+-----+---+-----------+-------------------+-------------+----------+------+------------+--------------------+\n",
      "|     author|                body|controversiality|        created_utc|distinguished|downs|gilded|  link_id| parent_id|       retrieved_on|score|ups|   username|      acct_creation|comment_karma|link_karma|is_bot|created_time|            body_vec|\n",
      "+-----------+--------------------+----------------+-------------------+-------------+-----+------+---------+----------+-------------------+-----+---+-----------+-------------------+-------------+----------+------+------------+--------------------+\n",
      "|-El-Zilcho-|You come up with ...|               0|2017-10-30 22:42:36|         null|    0|     0|t3_79qrlp|t1_dp4kl2j|2017-11-10 15:08:19|   12|  0|-El-Zilcho-|2012-06-28 18:27:27|         2292|        63| False|      224236|you come up with ...|\n",
      "|-El-Zilcho-|Lol lmfao hahaha....|               1|2017-11-28 21:53:46|         null|    0|     0|t3_7g7ai2|t1_dqhkuke|2017-12-12 14:50:39|    0|  0|-El-Zilcho-|2012-06-28 18:27:27|         2292|        63| False|      215346|   lol lmfao hahaha |\n",
      "|-LOLOCAUST-|Except when you g...|               0|2018-11-08 07:04:12|         null|    0|     0|t3_9v5cny|t1_e9a10rd|2018-12-18 05:08:18|    1|  0|-LOLOCAUST-|2013-04-08 06:36:21|        27539|      3063| False|       70412|except when you g...|\n",
      "|-LOLOCAUST-|This is sufficien...|               0|2017-11-09 07:40:07|         null|    0|     0|t3_7brzef|t1_dpkd7aj|2017-12-05 02:24:22|    4|  0|-LOLOCAUST-|2013-04-08 06:36:21|        27539|      3063| False|       74007|this is sufficien...|\n",
      "|-LOLOCAUST-|The best laws mon...|               0|2018-04-22 08:56:59|         null|    0|     0|t3_8dwka6|t1_dxqq04q|2018-05-17 21:46:20|    1|  0|-LOLOCAUST-|2013-04-08 06:36:21|        27539|      3063| False|       85659|the best laws mon...|\n",
      "+-----------+--------------------+----------------+-------------------+-------------+-----+------+---------+----------+-------------------+-----+---+-----------+-------------------+-------------+----------+------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "#import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#this code courtesy of http://michael-harmon.com/blog/SentimentAnalysisP2.html\n",
    "\n",
    "class PorterStemming(Transformer, HasInputCol, HasOutputCol):\n",
    "    \"\"\"\n",
    "    PosterStemming class using the NLTK Porter Stemmer\n",
    "    \n",
    "    This comes from https://stackoverflow.com/questions/32331848/create-a-custom-transformer-in-pyspark-ml\n",
    "    Adapted to work with the Porter Stemmer from NLTK.\n",
    "    \"\"\"\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, \n",
    "                 inputCol  : str = None, \n",
    "                 outputCol : str = None, \n",
    "                 min_size  : int = None):\n",
    "        \"\"\"\n",
    "        Constructor takes in the input column name, output column name,\n",
    "        plus the minimum legnth of a token (min_size)\n",
    "        \"\"\"\n",
    "        # call Transformer classes constructor since were extending it.\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # set Parameter objects minimum token size\n",
    "        self.min_size = Param(self, \"min_size\", \"\")\n",
    "        self._setDefault(min_size=0)\n",
    "\n",
    "        # set the input keywork arguments\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "        # initialize Stemmer object\n",
    "        self.stemmer  = PorterStemmer()\n",
    "\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self, \n",
    "                  inputCol  : str = None, \n",
    "                  outputCol : str = None, \n",
    "                  min_size  : int = None\n",
    "      ) -> None:\n",
    "        \"\"\"\n",
    "        Function to set the keyword arguemnts\n",
    "        \"\"\"\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "\n",
    "    def _stem_func(self, words  : list) -> list:\n",
    "        \"\"\"\n",
    "        Stemmer function call that performs stemming on a\n",
    "        list of tokens in words and returns a list of tokens\n",
    "        that have meet the minimum length requiremnt.\n",
    "        \"\"\"\n",
    "        # We need a way to get min_size and cannot access it \n",
    "        # with self.min_size\n",
    "        min_size       = self.getMinSize()\n",
    "\n",
    "        # stem that actual tokens by applying \n",
    "        # self.stemmer.stem function to each token in \n",
    "        # the words list\n",
    "        stemmed_words  = map(self.stemmer.stem, words)\n",
    "\n",
    "        # now create the new list of tokens from\n",
    "        # stemmed_words by filtering out those\n",
    "        # that are not of legnth > min_size\n",
    "        filtered_words = filter(lambda x: len(x) > min_size, stemmed_words)\n",
    "\n",
    "        return list(filtered_words)\n",
    "    \n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Transform function is the method that is called in the \n",
    "        MLPipleline.  We have to override this function for our own use\n",
    "        and have it call the _stem_func.\n",
    "\n",
    "        Notice how it takes in a type DataFrame and returns type Dataframe\n",
    "        \"\"\"\n",
    "        # Get the names of the input and output columns to use\n",
    "        out_col       = self.getOutputCol()\n",
    "        in_col        = self.getInputCol()\n",
    "\n",
    "        # create the stemming function UDF by wrapping the stemmer \n",
    "        # method function\n",
    "        stem_func_udf = F.udf(self._stem_func, ArrayType(StringType()))\n",
    "        \n",
    "        # now apply that UDF to the column in the dataframe to return\n",
    "        # a new column that has the same list of words after being stemmed\n",
    "        df2           = df.withColumn(out_col, stem_func_udf(df[in_col]))\n",
    "\n",
    "        return df2\n",
    "  \n",
    "  \n",
    "    def setMinSize(self,value):\n",
    "        \"\"\"\n",
    "        This method sets the minimum size value\n",
    "        for the _paramMap dictionary.\n",
    "        \"\"\"\n",
    "        self._paramMap[self.min_size] = value\n",
    "        return self\n",
    "\n",
    "    def getMinSize(self) -> int:\n",
    "        \"\"\"\n",
    "        This method uses the parent classes (Transformer)\n",
    "        .getOrDefault method to get the minimum\n",
    "        size of a token.\n",
    "        \"\"\"\n",
    "        return self.getOrDefault(self.min_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover, IDF, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"body_vec\", outputCol=\"body_vec_token\")\n",
    "remover = StopWordsRemover(inputCol = \"body_vec_token\", outputCol = \"body_vec_token_nosw\")\n",
    "stemmer = PorterStemming(inputCol = \"body_vec_token_nosw\", outputCol = \"body_vec_cleaned\")\n",
    "hashingTF = HashingTF(inputCol=\"body_vec_cleaned\", outputCol=\"body_vec_tf\", numFeatures=100)\n",
    "idf = IDF(inputCol=\"body_vec_tf\", outputCol=\"body_vec_tfidf\")\n",
    "label_stringIdx = StringIndexer(inputCol = \"is_bot\", outputCol = \"label\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, stemmer, hashingTF,idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 ms, sys: 54.8 ms, total: 200 ms\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%time nlpdf = pipeline.fit(df_raw).transform(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['controversiality', 'ups', 'downs', 'gilded', \n",
    "                                       'created_time', 'comment_karma','link_karma',\n",
    "                                        'score'], outputCol='features')\n",
    "nlpdf = assembler.transform(nlpdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlpdf = df_raw.drop('body_vec')\n",
    "# nlpdf = df_raw.drop('body_vec_token')\n",
    "# nlpdf = df_raw.drop('body_vec_token_nosw')\n",
    "# nlpdf = df_raw.drop('body_vec_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      body_vec_tfidf|\n",
      "+--------------------+\n",
      "|(100,[1,10,30],[2...|\n",
      "|(100,[30,39,40,44...|\n",
      "|(100,[6,48,49,70,...|\n",
      "|(100,[19,30,38,43...|\n",
      "|(100,[3,4,8,9,10,...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlpdf.select('body_vec_tfidf').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- controversiality: integer (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- downs: integer (nullable = false)\n",
      " |-- gilded: integer (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- retrieved_on: timestamp (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- ups: integer (nullable = false)\n",
      " |-- username: string (nullable = true)\n",
      " |-- acct_creation: timestamp (nullable = true)\n",
      " |-- comment_karma: integer (nullable = true)\n",
      " |-- link_karma: integer (nullable = true)\n",
      " |-- is_bot: string (nullable = true)\n",
      " |-- created_time: integer (nullable = true)\n",
      " |-- body_vec: string (nullable = true)\n",
      " |-- body_vec_token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- body_vec_token_nosw: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- body_vec_cleaned: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- body_vec_tf: vector (nullable = true)\n",
      " |-- body_vec_tfidf: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlpdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test and ensure label classes are stratified\n",
    "#train_df_notbanned, test_df_notbanned = nlpdf.filter(nlpdf.label==0).sample(False,0.0001,seed=5).randomSplit([0.8, 0.2])\n",
    "train_df_notbanned, test_df_notbanned = nlpdf.filter(nlpdf.label==0).randomSplit([0.8, 0.2])\n",
    "train_df_banned, test_df_banned = nlpdf.filter(nlpdf.label==1).randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unioning training sets and test sets\n",
    "train_df = train_df_notbanned.union(train_df_banned)\n",
    "test_df = test_df_notbanned.union(test_df_banned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training set sample 431\n",
      "length of test set 107\n"
     ]
    }
   ],
   "source": [
    "# sample_train = train_df.cache()\n",
    "# sample_test = test_df.cache()\n",
    "\n",
    "# print(\"length of training set sample {}\".format(sample_train.count()))\n",
    "# print(\"length of test set {}\".format(sample_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to run: 8.967144966125488\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "start = time.time()\n",
    "# Set parameters for Logistic Regression\n",
    "lgr = LogisticRegression(maxIter=10, featuresCol = 'body_vec_tfidf', labelCol='label')\n",
    "\n",
    "# Fit the model to the data.\n",
    "lgrm = lgr.fit(train_df)\n",
    "#lgrm = lgr.fit(sample_train)\n",
    "end = time.time()\n",
    "print('time to run: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 0.9626168224299065\n",
      "prediction f1 score: 0.9626168224299065\n",
      "time to run: 2.2132484912872314\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Given a dataset, predict each point's label, and show the results.\n",
    "predictions = lgrm.transform(test_df)\n",
    "#predictions = lgrm.transform(sample_test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "print('prediction accuracy: {}'\\\n",
    "          .format(evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})))\n",
    "print('prediction f1 score: {}'\\\n",
    "          .format(evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})))\n",
    "end = time.time()\n",
    "print('time to run: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = predictions.select('label').collect()\n",
    "# y_pred = predictions.select('prediction').collect()\n",
    "# true_list = [result.label for result in y_true]\n",
    "# pred_list = [result.prediction for result in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.98      0.98       105\n",
      "        1.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.96      0.96      0.96       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# print(classification_report(true_list, pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "# Set parameters for the Random Forest.\n",
    "rfc = RandomForestClassifier(maxDepth=5, numTrees=15, impurity=\"gini\", featuresCol='features',\n",
    "                             labelCol=\"label\")\n",
    "\n",
    "# Fit the model to the data.\n",
    "rfcm = rfc.fit(train_df)\n",
    "\n",
    "# Given a dataset, predict each point's label, and show the results.\n",
    "rfpredictions = rfcm.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy: 1.0\n",
      "prediction f1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('prediction accuracy: {}'\\\n",
    "          .format(evaluator.evaluate(rfpredictions, {evaluator.metricName: \"accuracy\"})))\n",
    "print('prediction f1 score: {}'\\\n",
    "          .format(evaluator.evaluate(rfpredictions, {evaluator.metricName: \"f1\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = rfpredictions.select('label').collect()\n",
    "# y_pred = rfpredictions.select('prediction').collect()\n",
    "# true_list = [result.label for result in y_true]\n",
    "# pred_list = [result.prediction for result in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       105\n",
      "        1.0       1.00      1.00      1.00         2\n",
      "\n",
      "avg / total       1.00      1.00      1.00       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# print(classification_report(true_list, pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
